{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Honglu Xu\n",
    "<br>\n",
    "EECS 491\n",
    "<br>\n",
    "Final Projest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Artificial Neural Networks on AIs to Play Video Games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Same part with EECS 531:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: This is a project that cannot all implemented in the Jupyter Notebook, and it is too hard to separate the code and copy them into the notebook, so there will not be any code showing in this notebook. All the file-names and descriptions are listed below, and I will try to explain the code part as clear as possible.\n",
    "<br>\n",
    "Please make sure you have correctly the configured your envirionment before you run the code. The main packages that will be needed are: \"pygame\", \"numpy\", \"pgmpy\", \"keras\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files:\n",
    "1. Snake.py: Main game file. Contains all the modules needed to run the game.\n",
    "2. VisionNN.py: Vision part of nerual networks. AI model for get input data from the screen pixels.\n",
    "3. InputAgent.py: Auto input agent for naive logic game input generations. Will be used to train the logic AI.\n",
    "4. LogicNN.py: Logic part of nerual networks. Will be used to generate output (player input) through the ANN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a game video AI, we firstly need to build a game. In this project, I will use the package \"pygame\" as the game engine. \n",
    "<br>\n",
    "The main game logic is simple. As long as we are running the game, it will:\n",
    "1. Check all the input I/O from the player/system.\n",
    "2. Update the game, which will apply all the inputs on the game and calculate all the data for next frame.\n",
    "3. Render the next frame.\n",
    "4. Keep looping from step 1 until end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game I will use for my experiment is \"Snake\". I chooese it for several reasons.\n",
    "1. It is easy to implement. \n",
    "<br>\n",
    "The snake is sort of an simple game. We might have encountered this game many times, we are familiar with it, and since it is in 2D and block based, we do not have many rendering part.\n",
    "2. Game logic is simple enough for a simple AI. \n",
    "<br>\n",
    "The game logic for snake is simple, for the player part, the input should be in 5 statement: \"up key\", \"down key\", \"left key\", \"right key\" and the \"r key\" for restart the game. And the output (feedback) should also be simple: survived (continue the game), ate the apple, and died. Thus, we have 5 input and 3 feedback statement, which should be simple enough for a starter experment.\n",
    "3. Game logic can also be complicated.\n",
    "<br>\n",
    "The game can also be complicated if we want to behave very good on this game. Sometimes we surrounded ourselves as a circle, then that area is a \"trap\", we should avoid our snake goes in. Sometimes we need to go through a narrow path that seems dangerours. Sometimes we need to count the steps so we can survive just one step early. Thus, it also can be a complicated game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the original game scree capture. I used the code from the tutorial of Python official site [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./pic/EECS531_fp_p1.jpeg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Game Tags:\n",
    "<br>\n",
    "If you want to try the code, you might need to configure the game tags that in \"Snake.py\" so that it will work as you wanted. Here is the list and descriptions of the game tags.\n",
    "1. using_AI: Main tag that will enable or disable all the logic AI.\n",
    "2. AI_type: Logic part AI type.\n",
    "<br>\n",
    "random: Randomly generating inputs.\n",
    "<br>\n",
    "bys1: Decision trees with believe network.\n",
    "<br>\n",
    "beta: Alpha-beta algorithms.\n",
    "<br>\n",
    "bys1nbeta: using both bys1 and beta\n",
    "<br>\n",
    "NN1: Neural network model1.\n",
    "<br>\n",
    "NN2: Neural network model2.\n",
    "3. beta_step: Step configuration for alpha-beta.\n",
    "4. train_Model: Logic models that will be used for taining.\n",
    "5. critical_train: Train logic models only in the critical condition.\n",
    "6. reading_Model: Reading logic models from file (file name hardcoded).\n",
    "7. test_Model: Logic models that will be used for testing.\n",
    "<br>\n",
    "8. using_VS: Main tag that will enable or disable all the vision AI.\n",
    "9. Vision_type: Vision part AI type.\n",
    "<br>\n",
    "NN1: Neural network model1.\n",
    "10. train_VModel: Vision models that will be used for taining.\n",
    "11. critical_vtrain: Train vision models only in the critical condition.\n",
    "12. reading_VModel: Reading vision models from file (file name hardcoded).\n",
    "13. test_VModel: Vision models that will be used for testing.\n",
    "\n",
    "For default, you can disable all the tags, then enable it one by one to see if it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For EECS491"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As stated in the EECS531 FP, I changed the color of the game to grayscale, so the components can be easier to detect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. First approach: Game agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model will be shown as the name of \"random\" for the logic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To give the AI the power to control the game, we need let the AI access the game control system. Fortunatly, we build the game ourselves, so we can left some APIs to the AI as it can control the game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the game agent, we can use the simplest kind of agent ---- random generation agent, to test is it's work able. Basiclly, this will generate 4 values, which stands for move-up, move-down, move-left and move-right, which are 4 basic inputs for the snake game."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pic/EECS491_fp_p1.gif\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above animation that we can not control the snake with inputs that generated by the agent, and since it is automatically generated, we can use that to train the neural network we will build later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Decision tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model will be shown as \"bys1\" as the name of logic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most common way to build an AI for the game is use the decision tree. It works similar as the state machine, and it always did good on some simple logics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, I used the bayesian network package \"pgmpy.models.BayesianModel\" to bulid a network as the decision tree, so we can use weights on it and see what will happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pic/EECS491_fp_p2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the decision tree that I made for the game. We have these variables:\n",
    "<br>\n",
    "EU: Enemy is above within one block.\n",
    "<br>\n",
    "ED: Enemy is down within one block.\n",
    "<br>\n",
    "EL: Enemy is left within one block.\n",
    "<br>\n",
    "ER: Enemy is Right within one block.\n",
    "<br>\n",
    "AU: Apple is up generally.\n",
    "<br>\n",
    "AD: Apple is down generally.\n",
    "<br>\n",
    "AL: Apple is left generally.\n",
    "<br>\n",
    "AR: Apple is right generally.\n",
    "<br>\n",
    "GO: Game Over.\n",
    "<br>\n",
    "MU: To move up.\n",
    "<br>\n",
    "MD: To move down.\n",
    "<br>\n",
    "ML: To move left.\n",
    "<br>\n",
    "MR: To move right.\n",
    "<br>\n",
    "R: Press 'R' to restart the game.\n",
    "<br>\n",
    "If the sign is '-', I will give nagative weights on this edge.\n",
    "<br>\n",
    "If the sign is '+', I will give positive weights on this edge.\n",
    "<br>\n",
    "Use the first tree as an example. If the enemy is up within one block, we definatly won't move up. But if there is an apple in that direction, we might try to move up.\n",
    "<br>\n",
    "Here, the enemy means all the elements that will make the snake die, which will contain, all the wall blocks, and all the tail blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pic/EECS491_fp_p3.gif\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this is already a not bad AI. It knows to get the apple, and it knows to avoid critical damage for 1 step. However, since the judgement of the enemy is just for 1 step, it cannot predict whether it is going into a \"trap\" or surround itselves that can never get out. Thus, more work will be needed for a better AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Alpha-beta algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model will be presented as name of \"beta\" in the logic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pic/EECS491_fp_p4.png\">\n",
    "[2] Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The a-b algorithm is mostly used for steps predicting for many situations. By using this algorithm, the AI can generate all the situations for next few steps, marks them as scores, and decied which step will lead to the trail taht have most winning possibilitiy. A common usage is an AI in the chess game, which it can generate all the steps that pissibile based on the current state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this situation we don't have enemies that will take steps to move, so all the situation is sigle sided. We only need to maximize the snake's steps, and it will be good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pic/EECS491_fp_p5.gif\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see this time, the AI is much more careful right now. Since we set the prediction step as 5. It can only predict next 5 steps. It will efficiently avoiding some dangerages \"traps\", but if the apple is not reachable for 5 steps, it will not know where to go. Also, if the AI think it is very dangerages to take the apple, it rather not taking it. That's why at the at end, it is looping all the time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Combine decision tree and Alpha-beta algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model will be presented as name of \"bys1nbeta\" in logic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sicne we know the pros and cons for these two algorithms now. We could combine these two method and extract all the advantages from both of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the decision tree will lead the main direction to the apple, and the a-b algorithm will avoid cirtical death for next few steps. We could use the decision tree as the main guide, and if the a-b algorirhm detected some bad things, we could avoid it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pic/EECS491_fp_p6.gif\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that now, it not only know where to go, it also trying to be very careful not went into any traps that can be detected within 5 steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Using ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model will be presented as \"NN1\" and \"NN2\" in the logic model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a sort of decent AI for the snake game, but it is far enough from our goal. What we want ot built, is that a genetic AI that can be used on many different games. Which should have the abilities of:\n",
    "1. Not based on any internal game data.\n",
    "2. Should be able to suit many different types of game input logic, should not be restricted to 'EU', 'ED', 'AP' these things.\n",
    "3. Should be able to suit many different types of game output logic, not only we could move around, for some games we should be able to 'jump', or even fire weapon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's why the goal for this project is to use the ANN. That means we train the AI with a certain rules and feedbacks (getting hurt, getting score), it could obey the rules and persuit the positive feedbacks. A lot of possible solutions I have come up with, such as using RNN and time based modules. Unfortunately, I am running out of time for this project. Thus, I will try to implement some simple solutions at least."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simple way is to use the decision tree to train the neural networks. The decision tree is pretty straight foward, so the AI should be able to understand the logic easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pic/EECS491_fp_p7.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the neural network I used for the simple approach. Since we will use the decision tree to train the neural network, it will make sense that we have the same inputs and outputs for this networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pic/EECS491_fp_p8.gif\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that indeed, it is following the rules of the decision tree. We can confirm at this is working right now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, since the decision tree is such a simple logic, which is generated by only 1 edge layer. i want to see whether it is possible to use only one inner layer of neural network to learn this basic idea. I reduced the network above to only one inner layer with 16 nodes, and the result shows below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pic/EECS491_fp_p9.gif\" width=\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though in theory, it should work, but actually it seems not well trained. There are many basic mistakes that should not occur, but happened on this AI. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is only a simple approach for the AI. There are still a lot to do next. To train the AI with a-b algorithm, since it is steps based, we should use the RNN instead of Dense. And similar to the combination of these methods, we could combine these two neural networks together to see what will happen. Also, to generate more intelligent data, we could use our onw plays as the input data to train the AI. Finally, we should get rid of all the internal game logics, and use the CV module as the input, the feedback (whether it survives, whether it hit the wall, whether it ate the apple) as the regression, and built a genetic AI that can be used for many different video games."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Python Official Site, *Snake with Pygame*, https://pythonspot.com/snake-with-pygame/\n",
    "<br>\n",
    "[2] Wikipedia, *Alpha–beta pruning*, https://en.wikipedia.org/wiki/Alpha%E2%80%93beta_pruning "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
